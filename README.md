# TechSphere ML API

API para an√°lisis de textos cient√≠ficos utilizando SciBERT con arquitectura por capas y **soporte para exposici√≥n p√∫blica con Ngrok**.

## üöÄ Caracter√≠sticas

- **Clasificaci√≥n de textos cient√≠ficos** con modelo SciBERT entrenado
- **üÜï Procesamiento batch de archivos CSV** con m√©tricas de evaluaci√≥n
- **üÜï Descarga de resultados procesados** con predicciones multilabel
- **Dashboard interactivo** con m√©tricas principales (F1-score, Accuracy)
- **Matriz de confusi√≥n visual** para an√°lisis de rendimiento
- **Gr√°ficos de distribuci√≥n** de clases m√©dicas
- **Demo funcional** para probar clasificaciones en tiempo real
- **Visualizaci√≥n de caracter√≠sticas** m√°s importantes del modelo
- **üåê Exposici√≥n p√∫blica con Ngrok** para acceso desde internet
- **üìä Panel de monitoreo** de t√∫neles Ngrok en tiempo real
- **üìà M√©tricas multilabel avanzadas** (Hamming Loss, Exact Match Ratio)
- **‚ö° Clasificaci√≥n con umbral configurable** para ajustar sensibilidad

## üèóÔ∏è Arquitectura

La API sigue una arquitectura por capas bien definida:

```
api/
‚îú‚îÄ‚îÄ controllers/     # Manejo de solicitudes HTTP
‚îú‚îÄ‚îÄ services/       # L√≥gica de negocio
‚îú‚îÄ‚îÄ models/         # Estructuras de datos y validaci√≥n
‚îî‚îÄ‚îÄ core/          # Configuraci√≥n y utilidades
```

### Capas:

- **Controllers**: Manejan solicitudes y respuestas HTTP
- **Services**: Implementan l√≥gica de negocio y coordinan operaciones
- **Models**: Definen estructuras de datos y reglas de validaci√≥n con Pydantic
- **Core**: Proporcionan utilidades y configuraci√≥n fundamentales

## üì¶ Instalaci√≥n

### Opci√≥n 1: Con Virtual Environment (Recomendado) üêç

1. **Clonar el repositorio** (o usar el directorio actual)

2. **Crear y activar entorno virtual**:

   ```bash
   # Crear entorno virtual
   python -m venv techsphere-env

   # Activar entorno virtual
   # En macOS/Linux:
   source techsphere-env/bin/activate

   # En Windows:
   techsphere-env\Scripts\activate

   # Verificar que est√° activado (deber√≠a aparecer (techsphere-env) en el prompt)
   ```

3. **Actualizar pip e instalar dependencias**:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Verificar que el modelo est√° disponible**:
   ```bash
   ls scibert_classifier/
   ```
   Debe contener: `config.json`, `model.safetensors`, `tokenizer.json`, etc.

### Opci√≥n 2: Con Conda (Alternativa recomendada) üêç

```bash
# Crear entorno conda
conda create -n techsphere python=3.10

# Activar entorno
conda activate techsphere

# Instalar dependencias
pip install -r requirements.txt
```

### Opci√≥n 3: Instalaci√≥n Global (No recomendado) ‚ö†Ô∏è

Si prefieres instalar globalmente:

```bash
pip install -r requirements.txt
```

**Nota**: La instalaci√≥n global puede causar conflictos con otros proyectos Python.

### ‚úÖ Verificar Instalaci√≥n

```bash
# Verificar que FastAPI se instal√≥ correctamente
python -c "import fastapi; print('FastAPI version:', fastapi.__version__)"

# Verificar que PyTorch se instal√≥ correctamente
python -c "import torch; print('PyTorch version:', torch.__version__)"

# Verificar que transformers se instal√≥ correctamente
python -c "import transformers; print('Transformers version:', transformers.__version__)"
```

## üöÄ Uso

### Activar Entorno Virtual

**¬°IMPORTANTE!** Siempre activa el entorno virtual antes de ejecutar el proyecto:

```bash
# Si usaste venv:
source techsphere-env/bin/activate

# Si usaste conda:
conda activate techsphere

# Verificar que est√° activado (debe aparecer el nombre del entorno en el prompt)
```

### Ejecutar la API

#### üíª Ejecuci√≥n Local

```bash
# Opci√≥n 1: Usando el script
python run_api.py

# Opci√≥n 2: Usando uvicorn directamente
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

La API estar√° disponible en: `http://localhost:8000`

#### üåê Ejecuci√≥n P√∫blica con Ngrok

Para hacer tu API accesible desde internet:

```bash
# Configuraci√≥n r√°pida (solo la primera vez)
./setup_ngrok.sh

# Ejecutar con Ngrok
python run_api.py --ngrok

# Con token espec√≠fico
python run_api.py --ngrok --ngrok-token TU_TOKEN

# Puerto personalizado
python run_api.py --ngrok --port 8080
```

**Cuando uses Ngrok obtendr√°s:**

- üåê **URL p√∫blica**: `https://abc123.ngrok-free.app`
- üìñ **Documentaci√≥n**: `https://abc123.ngrok-free.app/api/v1/docs`
- üîß **Panel de control**: `http://localhost:4040`

**Comandos √∫tiles:**

```bash
# Ver opciones disponibles
python run_api.py --help

# Demostraci√≥n completa interactiva
./demo_complete.sh

# Probar API p√∫blica
python ngrok_client_example.py https://tu-url-ngrok.app
```

### Documentaci√≥n interactiva

- **Swagger UI**: `http://localhost:8000/api/v1/docs`
- **ReDoc**: `http://localhost:8000/api/v1/redoc`

### Desactivar Entorno Virtual

Cuando termines de trabajar:

```bash
# Para venv y conda:
deactivate
```

## üìã Endpoints principales

### ü§ñ Machine Learning

- `POST /api/v1/ml/predict` - Clasificar texto cient√≠fico individual
- `POST /api/v1/ml/predict-batch` - **NUEVO**: Clasificar lote de textos desde CSV
- `GET /api/v1/ml/download/{filename}` - **NUEVO**: Descargar archivo procesado
- `GET /api/v1/ml/metrics` - Obtener m√©tricas del modelo
- `GET /api/v1/ml/classes` - Listar clases disponibles

### üìä Analytics & Visualizaciones

- `GET /api/v1/analytics/confusion-matrix` - Matriz de confusi√≥n
- `GET /api/v1/analytics/class-distribution` - Distribuci√≥n de clases
- `GET /api/v1/analytics/feature-importance` - Caracter√≠sticas importantes
- `GET /api/v1/analytics/performance-over-time` - Rendimiento temporal
- `GET /api/v1/analytics/category-correlations` - Correlaciones entre categor√≠as

### üîß System

- `GET /api/v1/health` - Health check
- `GET /api/v1/info` - Informaci√≥n de la API

## üß™ Ejemplo de uso

### Clasificar texto cient√≠fico individual

```bash
curl -X POST "http://localhost:8000/api/v1/ml/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Mechanisms of myocardial ischemia induced by epinephrine: comparison with exercise-induced ischemia The role of epinephrine in eliciting myocardial ischemia was examined in patients with coronary artery disease. Objective signs of ischemia and factors increasing myocardial oxygen consumption were compared during epinephrine infusion and supine bicycle exercise.",
       "threshold": 0.5
     }'
```

### üÜï **Clasificar lote de textos desde CSV**

**Paso 1: Preparar archivo CSV**

Crear un archivo `data.csv` con las siguientes columnas requeridas:

- `title`: T√≠tulo del art√≠culo cient√≠fico
- `abstract`: Resumen del art√≠culo cient√≠fico
- `group`: Categor√≠as reales (separadas por "|" para multilabel, ej: "cardiovascular|neurological")

```csv
title,abstract,group
"Mechanisms of myocardial ischemia","The role of epinephrine in eliciting myocardial ischemia was examined in patients with coronary artery disease...","cardiovascular"
"Brain tumor classification","Deep learning approaches have shown promising results in medical image analysis particularly for brain tumor detection...","neurological"
"Hepatocellular carcinoma treatment","This retrospective study analyzed treatment outcomes in patients with advanced hepatocellular carcinoma...","hepatorenal|oncological"
```

**Paso 2: Enviar archivo CSV para procesamiento**

```bash
curl -X POST "http://localhost:8000/api/v1/ml/predict-batch" \
     -H "accept: application/json" \
     -F "file=@data.csv" \
     -F "threshold=0.4"
```

**Paso 3: Descargar archivo procesado**

```bash
# Usar la URL proporcionada en la respuesta
curl -X GET "http://localhost:8000/api/v1/ml/download/predictions_YYYYMMDD_HHMMSS.csv" \
     --output predictions_results.csv
```

**Resultado**: El archivo descargado incluir√° las columnas originales m√°s:

- `group_predicted`: Categor√≠as predichas por el modelo
- `confidence`: Nivel de confianza de la predicci√≥n
- `combined_text`: Texto combinado usado para la predicci√≥n (title + abstract)

### Obtener m√©tricas del modelo

```bash
curl "http://localhost:8000/api/v1/ml/metrics"
```

### Obtener matriz de confusi√≥n

```bash
curl "http://localhost:8000/api/v1/analytics/confusion-matrix"
```

## üéØ Categor√≠as de clasificaci√≥n

El modelo clasifica textos en las siguientes categor√≠as m√©dicas:

- **cardiovascular**: Estudios del sistema cardiovascular
- **neurological**: Investigaciones del sistema nervioso
- **oncological**: Estudios relacionados con c√°ncer
- **hepatorenal**: Investigaciones de h√≠gado y ri√±ones

Tambi√©n identifica **combinaciones** de categor√≠as (clasificaci√≥n multilabel).

## üîç Estructura de respuestas

### Predicci√≥n individual

```json
{
  "predicted_class": "cardiovascular|neurological",
  "confidence": 0.87,
  "probabilities": {
    "cardiovascular": 0.45,
    "neurological": 0.42,
    "oncological": 0.13,
    "hepatorenal": 0.05
  },
  "categories": ["cardiovascular", "neurological"]
}
```

### üÜï **Predicci√≥n batch**

```json
{
  "success": true,
  "message": "Procesamiento exitoso de 6 registros",
  "total_processed": 6,
  "metrics": {
    "accuracy": 0.9167,
    "precision": 0.9167,
    "recall": 0.9167,
    "f1_score": 0.9,
    "hamming_loss": 0.0833,
    "exact_match_ratio": 0.6667,
    "total_samples": 6,
    "category_metrics": {
      "cardiovascular": {
        "precision": 1.0,
        "recall": 0.6667,
        "f1_score": 0.8,
        "support": 3
      },
      "neurological": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "support": 2
      },
      "hepatorenal": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "support": 3
      },
      "oncological": {
        "precision": 0.6667,
        "recall": 1.0,
        "f1_score": 0.8,
        "support": 2
      }
    }
  },
  "download_url": "/api/v1/ml/download/predictions_20250825_223034.csv",
  "processing_time": 0.82
}
```

### M√©tricas del modelo

```json
{
  "f1_score": 0.89,
  "accuracy": 0.92,
  "precision": 0.91,
  "recall": 0.87,
  "total_classes": 15
}
```

## üõ†Ô∏è Desarrollo

### Estructura del proyecto

```
techsphere/
‚îú‚îÄ‚îÄ api/                    # C√≥digo de la API
‚îÇ   ‚îú‚îÄ‚îÄ controllers/        # Controladores HTTP
‚îÇ   ‚îú‚îÄ‚îÄ services/          # Servicios de negocio
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Modelos de datos
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ main.py           # Aplicaci√≥n principal
‚îú‚îÄ‚îÄ scibert_classifier/    # Modelo ML entrenado
‚îú‚îÄ‚îÄ main.py               # Script original del modelo
‚îú‚îÄ‚îÄ run_api.py           # Script para ejecutar API
‚îî‚îÄ‚îÄ requirements.txt     # Dependencias
```

### Agregar nuevas funcionalidades

1. **Nuevo endpoint**: Agregar en `controllers/`
2. **Nueva l√≥gica de negocio**: Implementar en `services/`
3. **Nuevos modelos de datos**: Definir en `models/schemas.py`
4. **Nueva configuraci√≥n**: Agregar en `core/config.py`

## üîí Producci√≥n

Para desplegar en producci√≥n:

1. **Configurar variables de entorno**
2. **Usar ASGI server** como Gunicorn + Uvicorn
3. **Configurar CORS** espec√≠ficamente
4. **Agregar autenticaci√≥n** si es necesario
5. **Configurar logging** apropiado
6. **Usar base de datos** para persistencia si se requiere

## ü§ù Contribuir

1. Fork el proyecto
2. Crear rama de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT.

---

**TechSphere ML API** - An√°lisis inteligente de textos cient√≠ficos üî¨üöÄ
